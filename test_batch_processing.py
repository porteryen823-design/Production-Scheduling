"""
æ‰¹æ¬¡åŠ å·¥åŠŸèƒ½æ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰ STEP5 çš„æ‰¹æ¬¡åŠ å·¥é‚è¼¯æ˜¯å¦æ­£ç¢ºé‹ä½œ
"""

import json
import os
import sys
import io
from datetime import datetime

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

def analyze_batch_processing_results():
    """åˆ†ææ’ç¨‹çµæœä¸­çš„æ‰¹æ¬¡åŠ å·¥æƒ…æ³"""
    
    result_file = "plan_result/LotStepResult.json"
    
    if not os.path.exists(result_file):
        print("âŒ æ‰¾ä¸åˆ°æ’ç¨‹çµæœæª”æ¡ˆï¼Œè«‹å…ˆåŸ·è¡Œæ’ç¨‹")
        return
    
    with open(result_file, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    # ç¯©é¸å‡º STEP5 çš„æ‰€æœ‰è¨˜éŒ„
    step5_records = [r for r in results if r['Step'] == 'STEP5']
    
    if not step5_records:
        print("âš ï¸  æ²’æœ‰æ‰¾åˆ° STEP5 çš„æ’ç¨‹è¨˜éŒ„")
        return
    
    print(f"\n{'='*80}")
    print(f"æ‰¹æ¬¡åŠ å·¥åˆ†æå ±å‘Š - STEP5")
    print(f"{'='*80}\n")
    print(f"ç¸½å…±æœ‰ {len(step5_records)} å€‹ Lots åœ¨ STEP5 åŠ å·¥\n")
    
    # æŒ‰ç…§é–‹å§‹æ™‚é–“åˆ†çµ„ï¼ˆåŒä¸€æ‰¹æ¬¡çš„ Lots é–‹å§‹æ™‚é–“ç›¸åŒï¼‰
    batches = {}
    for record in step5_records:
        start_time = record['Start']
        if start_time not in batches:
            batches[start_time] = []
        batches[start_time].append(record)
    
    print(f"è­˜åˆ¥å‡º {len(batches)} å€‹æ‰¹æ¬¡\n")
    print(f"{'-'*80}\n")
    
    # åˆ†ææ¯å€‹æ‰¹æ¬¡
    batch_num = 1
    for start_time, lots in sorted(batches.items()):
        print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_num}:")
        print(f"   é–‹å§‹æ™‚é–“: {start_time}")
        print(f"   æ‰¹æ¬¡å¤§å°: {len(lots)} å€‹ Lots")
        print(f"   Lot IDs: {', '.join([lot['LotId'] for lot in lots])}")
        
        # æª¢æŸ¥çµæŸæ™‚é–“æ˜¯å¦ä¸€è‡´
        end_times = set([lot['End'] for lot in lots])
        if len(end_times) == 1:
            print(f"   çµæŸæ™‚é–“: {end_times.pop()} âœ“ (æ‰€æœ‰ Lots åŒæ™‚çµæŸ)")
        else:
            print(f"   âš ï¸  è­¦å‘Šï¼šçµæŸæ™‚é–“ä¸ä¸€è‡´ï¼")
            for lot in lots:
                print(f"      - {lot['LotId']}: {lot['End']}")
        
        # è¨ˆç®—åŠ å·¥æ™‚é–“
        start_dt = datetime.fromisoformat(start_time)
        end_dt = datetime.fromisoformat(lots[0]['End'])
        duration = (end_dt - start_dt).total_seconds() / 60
        print(f"   åŠ å·¥æ™‚é–“: {duration:.0f} åˆ†é˜")
        
        # æª¢æŸ¥æ©Ÿå°
        machines = set([lot['Machine'] for lot in lots])
        if len(machines) == 1:
            print(f"   ä½¿ç”¨æ©Ÿå°: {machines.pop()} âœ“ (åŒä¸€å°æ©Ÿå™¨)")
        else:
            print(f"   ä½¿ç”¨æ©Ÿå°: {', '.join(machines)} (å¤šå°æ©Ÿå™¨)")
        
        print()
        batch_num += 1
    
    print(f"{'-'*80}\n")
    
    # é©—è­‰æ‰¹æ¬¡å¤§å°é™åˆ¶
    max_batch_size = int(os.getenv('BATCH_PROCESSING_MAX_SIZE', 2))
    oversized_batches = [b for b in batches.values() if len(b) > max_batch_size]
    
    if oversized_batches:
        print(f"âŒ ç™¼ç¾ {len(oversized_batches)} å€‹æ‰¹æ¬¡è¶…éå¤§å°é™åˆ¶ (MAX={max_batch_size})")
    else:
        print(f"âœ“ æ‰€æœ‰æ‰¹æ¬¡éƒ½ç¬¦åˆå¤§å°é™åˆ¶ (MAX={max_batch_size})")
    
    # è¨ˆç®—å¹³å‡æ‰¹æ¬¡å¤§å°
    avg_batch_size = sum(len(b) for b in batches.values()) / len(batches)
    print(f"âœ“ å¹³å‡æ‰¹æ¬¡å¤§å°: {avg_batch_size:.2f} å€‹ Lots")
    
    # è¨ˆç®—æ‰¹æ¬¡åˆ©ç”¨ç‡
    utilization = (avg_batch_size / max_batch_size) * 100
    print(f"âœ“ æ‰¹æ¬¡åˆ©ç”¨ç‡: {utilization:.1f}%")
    
    print(f"\n{'='*80}\n")

def check_waiting_time():
    """æª¢æŸ¥ç­‰å¾…æ™‚é–“æ˜¯å¦ç¬¦åˆé™åˆ¶"""
    
    result_file = "plan_result/LotStepResult.json"
    
    if not os.path.exists(result_file):
        return
    
    with open(result_file, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    max_wait_time = int(os.getenv('BATCH_PROCESSING_MAX_WAIT_MINUTES', 10))
    
    print(f"ç­‰å¾…æ™‚é–“åˆ†æ (ä¸Šé™: {max_wait_time} åˆ†é˜)")
    print(f"{'-'*80}\n")
    
    # ç‚ºæ¯å€‹ Lot æ‰¾åˆ° STEP4 å’Œ STEP5 çš„æ™‚é–“
    lots_data = {}
    for record in results:
        lot_id = record['LotId']
        if lot_id not in lots_data:
            lots_data[lot_id] = {}
        lots_data[lot_id][record['Step']] = {
            'Start': record['Start'],
            'End': record['End']
        }
    
    # è¨ˆç®—ç­‰å¾…æ™‚é–“ï¼ˆSTEP4 çµæŸåˆ° STEP5 é–‹å§‹ï¼‰
    violations = []
    for lot_id, steps in lots_data.items():
        if 'STEP4' in steps and 'STEP5' in steps:
            step4_end = datetime.fromisoformat(steps['STEP4']['End'])
            step5_start = datetime.fromisoformat(steps['STEP5']['Start'])
            wait_time = (step5_start - step4_end).total_seconds() / 60
            
            if wait_time > max_wait_time:
                violations.append((lot_id, wait_time))
            
            print(f"  {lot_id}: ç­‰å¾… {wait_time:.1f} åˆ†é˜", end="")
            if wait_time > max_wait_time:
                print(f" âŒ è¶…éé™åˆ¶")
            else:
                print(f" âœ“")
    
    print()
    if violations:
        print(f"âŒ ç™¼ç¾ {len(violations)} å€‹ Lots ç­‰å¾…æ™‚é–“è¶…éé™åˆ¶")
    else:
        print(f"âœ“ æ‰€æœ‰ Lots çš„ç­‰å¾…æ™‚é–“éƒ½åœ¨é™åˆ¶å…§")
    
    print(f"\n{'='*80}\n")

if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    print("\n" + "="*80)
    print("æ‰¹æ¬¡åŠ å·¥åŠŸèƒ½é©—è­‰å·¥å…·")
    print("="*80 + "\n")
    
    analyze_batch_processing_results()
    check_waiting_time()
    
    print("é©—è­‰å®Œæˆï¼\n")
